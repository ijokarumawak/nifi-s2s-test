
# NIO: Local Macbook to localhost
- 20190201_1244_1.csv: numOfClient=1, numOfTx=10, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=10, totalFailureTx=0, avgCreateTxMillis=58, avgSendMillis=1, avgConfirmMillis=1, avgCompleteMillis=1
- 20190201_1246_50.csv: numOfClient=50, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=15000, totalFailureTx=0, avgCreateTxMillis=7, avgSendMillis=0, avgConfirmMillis=1, avgCompleteMillis=1
- 20190201_1254_100.csv: numOfClient=100, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=30000, totalFailureTx=0, avgCreateTxMillis=10, avgSendMillis=0, avgConfirmMillis=1, avgCompleteMillis=1
- 20190201_1305_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=149874, totalFailureTx=126, avgCreateTxMillis=52, avgSendMillis=0, avgConfirmMillis=7, avgCompleteMillis=1
- 20190201_1404_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=149825, totalFailureTx=175, avgCreateTxMillis=53, avgSendMillis=0, avgConfirmMillis=5, avgCompleteMillis=1
    - Changed to VolatileProvenanceRepository, but still timeout happens.
    - Next, change InputPort threads from 8 to 16
- 20190201_1411_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=149868, totalFailureTx=132, avgCreateTxMillis=54, avgSendMillis=1, avgConfirmMillis=5, avgCompleteMillis=1
    - Still timeout occurs.
- 20190201_1446_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=149895, totalFailureTx=105, avgCreateTxMillis=56, avgSendMillis=1, avgConfirmMillis=4, avgCompleteMillis=1
    - After fixing SocketFlowFileServerProtocol's excessive INFO log, number of failures decreased slightly.
    - Next, use another machine for the client.
- 20190201_1532_10.csv: numOfClient=10, numOfTx=30, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=300, totalFailureTx=0, avgCreateTxMillis=138, avgSendMillis=1, avgConfirmMillis=123, avgCompleteMillis=28
    - Using different machine. But the network is freaky..
        ```
        # ping result
        68 packets transmitted, 67 packets received, 1.5% packet loss
        round-trip min/avg/max/stddev = 2.669/183.117/629.480/215.699 ms
        ```
- 20190201_1543_100.csv: numOfClient=100, numOfTx=30, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=2877, totalFailureTx=123, avgCreateTxMillis=289, avgSendMillis=0, avgConfirmMillis=24, avgCompleteMillis=8

# NIO: AWS EC2 instances
- 20190201_0812_100.csv: numOfClient=100, numOfTx=30, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=3000, totalFailureTx=0, avgCreateTxMillis=607, avgSendMillis=0, avgConfirmMillis=172, avgCompleteMillis=2
    - Using EC2 m5d.large instances. One for standalone NiFi and the other is this client test program.
- 20190201_0816_100.csv: numOfClient=100, numOfTx=30, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=3000, totalFailureTx=0, avgCreateTxMillis=638, avgSendMillis=0, avgConfirmMillis=43, avgCompleteMillis=1
- 20190201_0818_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=149295, totalFailureTx=705, avgCreateTxMillis=84, avgSendMillis=0, avgConfirmMillis=79, avgCompleteMillis=2
    - Lots of timeout happens with 500 clients. Does the server encounter any issue? Let's run it again.
- 20190201_0829_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=146506, totalFailureTx=3494, avgCreateTxMillis=97, avgSendMillis=0, avgConfirmMillis=114, avgCompleteMillis=2
    - Probably 500 clients are too much. Let's lower it to 300.
- 20190201_0840_300.csv: numOfClient=300, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=89625, totalFailureTx=375, avgCreateTxMillis=65, avgSendMillis=0, avgConfirmMillis=58, avgCompleteMillis=2
    - Still having timeouts. Let's try 200.
- 20190201_0851_200.csv: numOfClient=200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, 
    - It seems having more connection errors at the beginning. Probably both connection maintenance and create transaction try connecting at the same time. Added jitter.
- 20190201_0901_200.csv: numOfClient=200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=59995, totalFailureTx=5, avgCreateTxMillis=31, avgSendMillis=0, avgConfirmMillis=52, avgCompleteMillis=1
    - 200 client seems the maximum concurrency with this environment.

# SOCKET: with NiFi 1.8.0 on EC2
- 20190201_0923_200.csv: numOfClient=200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=60000, totalFailureTx=0, avgCreateTxMillis=2, avgSendMillis=0, avgConfirmMillis=44, avgCompleteMillis=1
    - The current implementation works just fine with 200 clients..
- 20190201_0931_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, 
    - UpdateAttribute caused backpressure S2S receiving rate exceeds UpdateAttribute.
    - For next: Increased UpdateAttribute batch duration to 1s.
- 20190201_0936_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, - 20190201_0937_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=107304, totalFailureTx=42696, avgCreateTxMillis=46, avgSendMillis=0, avgConfirmMillis=341, avgCompleteMillis=21
    - UpdateAttribute still causes backpressure.
    - [Site-to-Site Listener] o.a.nifi.remote.SocketRemoteSiteListener RemoteSiteListener Unable to accept connection due to java.io.IOException: Too many open files
    - For next: Increased UpdateAttribute concurrent tasks to 4 and max open files from 1024 to 10240
- 20190201_1058_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, 
    - Didn't finish.

# Thread/Conn: with JDK11 on EC2
- 20190204_0551_200.csv: numOfClient=200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=60000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=43, avgCompleteMillis=1
- 20190204_0558_400.csv: numOfClient=400, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=120000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=43, avgCompleteMillis=1
- 20190204_0614_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=150000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=44, avgCompleteMillis=1
- 20190204_0622_600.csv: numOfClient=600, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=180000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=44, avgCompleteMillis=1
- 20190204_0630_700.csv: numOfClient=700, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=210000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=46, avgCompleteMillis=1
- 20190204_0639_800.csv: numOfClient=800, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=240000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=46, avgCompleteMillis=2
- 20190204_0647_900.csv: numOfClient=900, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=270000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=47, avgCompleteMillis=2
- 20190204_0655_1000.csv: numOfClient=1000, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=300000, totalFailureTx=0, avgCreateTxMillis=2, avgSendMillis=0, avgConfirmMillis=49, avgCompleteMillis=2
    - Succeeded test with 1000 clients.
- 20190204_0704_1200.csv: numOfClient=1200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=358204, totalFailureTx=1796, avgCreateTxMillis=17, avgSendMillis=0, avgConfirmMillis=105, avgCompleteMillis=4
    - Server listener thread stops working due to OOM
- 20190204_0759_1100.csv: numOfClient=1100, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=329976, totalFailureTx=24, avgCreateTxMillis=2, avgSendMillis=0, avgConfirmMillis=64, avgCompleteMillis=2
    - After restarting NiFi, 1100 clients worked but some failure occurred.

# NIO from scratch
These tests used plain RAW connection (not secured) since secure connection hasn't implemented yet.
Just to confirm multiple clients work fine with a reasonable performance.
- 20190423_1406_10.csv: numOfClient=10, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=3000, totalFailureTx=0, avgCreateTxMillis=5, avgSendMillis=0, avgConfirmMillis=6, avgCompleteMillis=0
- 20190423_1424_100.csv: numOfClient=100, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=30000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=5, avgCompleteMillis=0
- 20190423_1432_200.csv: numOfClient=200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=60000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=6, avgCompleteMillis=0
- 20190423_1443_300.csv: numOfClient=300, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=90000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=6, avgCompleteMillis=1
- 20190423_1453_500.csv: numOfClient=500, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=150000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=11, avgCompleteMillis=3
- 20190423_1501_700.csv: numOfClient=700, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=210000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=164, avgCompleteMillis=7
- 20190423_1511_800.csv: numOfClient=800, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=240000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=1115, avgCompleteMillis=12
- 20190423_1539_1000.csv: numOfClient=1000, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, - 20190423_1542_1000.csv: numOfClient=1000, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=300000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=2009, avgCompleteMillis=16
- Increased input port concurrency from 4 to 6
- 20190423_1602_1200.csv: numOfClient=1200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=359258, totalFailureTx=742, avgCreateTxMillis=2, avgSendMillis=0, avgConfirmMillis=2660, avgCompleteMillis=25
- 20190423_1622_1200.csv: numOfClient=1200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=359043, totalFailureTx=957, avgCreateTxMillis=3, avgSendMillis=0, avgConfirmMillis=3082, avgCompleteMillis=28

2019-04-23 16:40:33,568 ERROR [NIO-Site-to-Site Listener] o.a.n.remote.nio.MessageSequenceHandler Failed to process mess
age due to org.apache.nifi.processor.exception.ProcessException: org.apache.nifi.remote.exception.RequestExpiredException
org.apache.nifi.processor.exception.ProcessException: org.apache.nifi.remote.exception.RequestExpiredException
        at org.apache.nifi.remote.StandardRootGroupPort.startReceivingFlowFiles(StandardRootGroupPort.java:443)
        at org.apache.nifi.remote.nio.s2s.ReceiveFlowFiles.lambda$new$0(ReceiveFlowFiles.java:53)
        at org.apache.nifi.remote.nio.stream.StreamData.prepare(StreamData.java:42)
        at org.apache.nifi.remote.nio.MessageSequenceHandler.processBuffers(MessageSequenceHandler.java:149)
        at org.apache.nifi.remote.nio.MessageSequenceHandler.selectKeys(MessageSequenceHandler.java:230)
        at org.apache.nifi.remote.nio.MessageSequenceHandler.start(MessageSequenceHandler.java:57)
        at org.apache.nifi.remote.nio.s2s.NIORemoteSiteListener.lambda$start$3(NIORemoteSiteListener.java:79)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.nifi.remote.exception.RequestExpiredException: null
        at org.apache.nifi.remote.StandardRootGroupPort.startReceivingFlowFiles(StandardRootGroupPort.java:434)
        ... 7 common frames omitted

# Profiling
- 20190424_0935_200.csv: numOfClient=200, numOfTx=300, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=59999, totalFailureTx=1, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=14, avgCompleteMillis=1
- 20190424_0942_200.csv: numOfClient=200, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=100000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=13, avgCompleteMillis=2
- Changed input port concurrency form 6 to 16.
- 20190424_0953_1000.csv: numOfClient=1000, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=499864, totalFailureTx=136, avgCreateTxMillis=11, avgSendMillis=0, avgConfirmMillis=1119, avgCompleteMillis=44
- Change Provenance Repo to volatile
- 20190424_1033_1000.csv: numOfClient=1000, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=499957, totalFailureTx=43, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=558, avgCompleteMillis=32
- 20190424_1054_1000.csv: numOfClient=1000, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=499941, totalFailureTx=59, avgCreateTxMillis=2, avgSendMillis=0, avgConfirmMillis=630, avgCompleteMillis=33

Does the server closes connections?
10:55:42.892 [Thread-913] ERROR com.rumawaks.nifi.s2s.test.S2SClient - Transaction failed due to java.net.SocketExceptio
n: Connection reset by peer
10:55:44.898 [Thread-913] ERROR com.rumawaks.nifi.s2s.test.S2SClient - Transaction failed due to java.lang.NullPointerEx
ception
10:55:46.150 [Thread-913] ERROR com.rumawaks.nifi.s2s.test.S2SClient - Transaction failed due to java.net.SocketException: Connection reset by peer
- 20190424_1128_1000.csv: numOfClient=1000, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=493946, totalFailureTx=6054, avgCreateTxMillis=4, avgSendMillis=0, avgConfirmMillis=421, avgCompleteMillis=30

# NIO 10 worker threads
- 20190424_1630_10.csv: numOfClient=10, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=0, totalFailureTx=5000, avgCreateTxMillis=-1, avgSendMillis=-1, avgConfirmMillis=-1, avgCompleteMillis=-1
- 20190424_1705_10.csv: numOfClient=10, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=5000, totalFailureTx=0, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=5, avgCompleteMillis=0
- 20190424_1719_1000.csv: numOfClient=1000, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=500000, totalFailureTx=0, avgCreateTxMillis=0, avgSendMillis=0, avgConfirmMillis=55, avgCompleteMillis=15
- 20190424_1731_1200.csv: numOfClient=1200, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, - 20190425_0832_1200.csv: numOfClient=1200, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=597886, totalFailureTx=2114, avgCreateTxMillis=1, avgSendMillis=0, avgConfirmMillis=1649, avgCompleteMillis=50
- The cause of failure was that StandardRootGroupPort failed to put new FlowFileRequest into its requestQueue which has size limitation as 1,000. That means it can support only 1000 concurrent requests.
```
2019-04-25 08:50:49,883 ERROR [NIOSiteToSite-IO-2] o.a.n.remote.nio.MessageSequenceHandler Failed to process message due to org.apache.nifi.processor.exception.ProcessException: org.apache.nifi.remote.exception.RequestExpiredException
org.apache.nifi.processor.exception.ProcessException: org.apache.nifi.remote.exception.RequestExpiredException
        at org.apache.nifi.remote.StandardRootGroupPort.startReceivingFlowFiles(StandardRootGroupPort.java:443)
        at org.apache.nifi.remote.nio.s2s.ReceiveFlowFiles.lambda$new$0(ReceiveFlowFiles.java:53)
```

## Increased requestQueue size to 10,000
- 20190425_0937_1200.csv: numOfClient=1200, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=583900, totalFailureTx=16100, avgCreateTxMillis=5, avgSendMillis=0, avgConfirmMillis=1705, avgCompleteMillis=50
- 20190425_1005_1200.csv: numOfClient=1200, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000,
- 20190425_1043_1200.csv: numOfClient=1200, numOfTx=500, numOfPacketsPerTx=5, txIntervalMillis=1000, totalSuccessfulTx=564386, totalFailureTx=35614, avgCreateTxMillis=6, avgSendMillis=0, avgConfirmMillis=1406, avgCompleteMillis=47

  10 java.io.IOException:Brokenpipe
   8 java.io.IOException:Connectionreset
   1 java.io.IOException:Protocolwrong
  52 java.net.ConnectException:Operationtimed
  19 java.net.SocketException:Connectionreset

